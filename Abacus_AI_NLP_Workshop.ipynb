{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "1ace4015",
      "metadata": {
        "id": "1ace4015",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5bdfb36a-96eb-4e04-a3ce-0cfe5ad13f52"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting abacusai\n",
            "  Downloading abacusai-0.36.4.tar.gz (3.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.4 MB 5.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from abacusai) (21.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from abacusai) (2.23.0)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from abacusai) (1.3.5)\n",
            "Collecting fastavro\n",
            "  Downloading fastavro-1.4.12-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.3 MB 38.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->abacusai) (3.0.9)\n",
            "Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.7/dist-packages (from pandas->abacusai) (1.21.6)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas->abacusai) (2022.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->abacusai) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas->abacusai) (1.15.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->abacusai) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->abacusai) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->abacusai) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->abacusai) (2021.10.8)\n",
            "Building wheels for collected packages: abacusai\n",
            "  Building wheel for abacusai (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for abacusai: filename=abacusai-0.36.4-py3-none-any.whl size=134875 sha256=790546d892e563664aceb95669e43e747669918ea0194c6a8a452998c470f130\n",
            "  Stored in directory: /root/.cache/pip/wheels/f5/30/4e/1f7d42e339242d63030a7622906e7377dbaff762bcafa211be\n",
            "Successfully built abacusai\n",
            "Installing collected packages: fastavro, abacusai\n",
            "Successfully installed abacusai-0.36.4 fastavro-1.4.12\n"
          ]
        }
      ],
      "source": [
        "!pip install -U abacusai"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "a1d5feac",
      "metadata": {
        "id": "a1d5feac"
      },
      "outputs": [],
      "source": [
        "import collections\n",
        "import threading\n",
        "import time\n",
        "\n",
        "from tqdm import tqdm\n",
        "import numpy as np\n",
        "import IPython.display\n",
        "\n",
        "import abacusai"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "13b5208a",
      "metadata": {
        "id": "13b5208a"
      },
      "source": [
        "# Set up API client and load data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "458ea55a",
      "metadata": {
        "id": "458ea55a"
      },
      "outputs": [],
      "source": [
        "api_key = '9aaf73ff552c4914b6a4642f46115cdc'\n",
        "server = 'https://abacus.ai'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "95995fa2",
      "metadata": {
        "id": "95995fa2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "74604fff-29df-4aba-915b-a2bc33c44f5c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<abacusai.client.ApiClient at 0x7fe35671dd90>"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "api_client = abacusai.ApiClient(api_key=api_key, server=server)\n",
        "api_client"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "78b567e6",
      "metadata": {
        "id": "78b567e6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "outputId": "c9902c95-cec3-48c0-d0a8-9013be101692"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                       vehicle_title  \\\n",
              "0  1997 Toyota Previa Minivan LE All-Trac 3dr Min...   \n",
              "1          1997 Toyota Previa Minivan LE 3dr Minivan   \n",
              "2  1997 Toyota Previa Minivan LE All-Trac 3dr Min...   \n",
              "3  1997 Toyota Previa Minivan LE All-Trac 3dr Min...   \n",
              "4  2007 Toyota Avalon Sedan XLS 4dr Sedan (3.5L 6...   \n",
              "\n",
              "                                        review_title  \\\n",
              "0                 my 4th previa, best van ever made!   \n",
              "1                             Mom's Taxi Babies Ride   \n",
              "2                                  Best Minivan ever   \n",
              "3               Final model year of the great Previa   \n",
              "4  I'll drive this car until they take it away fr...   \n",
              "\n",
              "                                              review  \n",
              "0   1st 95 went over 300k before being totalled b...  \n",
              "1   Sold 86 Toyota Van 285K miles to be replaced ...  \n",
              "2   My 1997 AWD Previa is the third one that I ha...  \n",
              "3   An amazing vehicle: mid-engine, supercharged,...  \n",
              "4   Bought this Avy in 2007 used with 1200 miles ...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-e202f81d-93ee-405a-9c95-f862576bc1f0\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>vehicle_title</th>\n",
              "      <th>review_title</th>\n",
              "      <th>review</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1997 Toyota Previa Minivan LE All-Trac 3dr Min...</td>\n",
              "      <td>my 4th previa, best van ever made!</td>\n",
              "      <td>1st 95 went over 300k before being totalled b...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1997 Toyota Previa Minivan LE 3dr Minivan</td>\n",
              "      <td>Mom's Taxi Babies Ride</td>\n",
              "      <td>Sold 86 Toyota Van 285K miles to be replaced ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1997 Toyota Previa Minivan LE All-Trac 3dr Min...</td>\n",
              "      <td>Best Minivan ever</td>\n",
              "      <td>My 1997 AWD Previa is the third one that I ha...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1997 Toyota Previa Minivan LE All-Trac 3dr Min...</td>\n",
              "      <td>Final model year of the great Previa</td>\n",
              "      <td>An amazing vehicle: mid-engine, supercharged,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2007 Toyota Avalon Sedan XLS 4dr Sedan (3.5L 6...</td>\n",
              "      <td>I'll drive this car until they take it away fr...</td>\n",
              "      <td>Bought this Avy in 2007 used with 1200 miles ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e202f81d-93ee-405a-9c95-f862576bc1f0')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-e202f81d-93ee-405a-9c95-f862576bc1f0 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-e202f81d-93ee-405a-9c95-f862576bc1f0');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "feature_group = api_client.describe_feature_group('10c6c17150')\n",
        "data = feature_group.load_as_pandas()\n",
        "data.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0935f2f8",
      "metadata": {
        "id": "0935f2f8"
      },
      "source": [
        "# Get predictions from sentiment model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "3ec2ade2",
      "metadata": {
        "id": "3ec2ade2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "202946e6-4e23-4ded-97a1-637824341189"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'admiration': 0.18734998114836707,\n",
              " 'amusement': 0.00015829608571614316,\n",
              " 'anger': 0.001131381759855807,\n",
              " 'annoyance': 0.09705089982431851,\n",
              " 'approval': 0.2514723889317682,\n",
              " 'caring': 0.0007489281076559976,\n",
              " 'confusion': 0.0007848413354010962,\n",
              " 'curiosity': 0.00039328829884743366,\n",
              " 'desire': 0.015303365088136841,\n",
              " 'disappointment': 0.8165182041561381,\n",
              " 'disapproval': 0.00733822621012426,\n",
              " 'disgust': 0.0005704679312483601,\n",
              " 'embarrassment': 0.00011633836868711977,\n",
              " 'excitement': 0.0012685498495989575,\n",
              " 'fear': 0.0002763517529304868,\n",
              " 'gratitude': 0.00023449238225218384,\n",
              " 'grief': 0.0007154216040626338,\n",
              " 'joy': 0.0019889361907007015,\n",
              " 'love': 0.00025728372515842725,\n",
              " 'nervousness': 0.0010029814916877676,\n",
              " 'neutral': 0.10354925047401577,\n",
              " 'optimism': 0.008917951741144722,\n",
              " 'pride': 0.0062754131669841,\n",
              " 'realization': 0.019385494946991308,\n",
              " 'relief': 0.0024816415701369478,\n",
              " 'remorse': 0.00281108329032291,\n",
              " 'sadness': 0.007259515837988566,\n",
              " 'surprise': 0.00025386384160559593}"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "from abacusai import PredictionClient\n",
        "client = PredictionClient()\n",
        "client.get_sentiment(deployment_token='dd6f423c5956422abf2c6cd07c21b071', deployment_id='643d34f0c', document=\" Toyotas will run forever and hybrid design is solid.The car is quiet and the seats are great.The interior build quality is terrible however.My headliner warped in the first 4K miles, the dash creaks and pops when you hit a dump and the door panels also creak constantly.A happy customer tells four people about their experience and unhappy customer tells 10 people.The crappy part is I have to sell it at a loss to buy the ford fusion.My gut told me to go with the ford and I should have followed it.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fd4c041f",
      "metadata": {
        "id": "fd4c041f"
      },
      "outputs": [],
      "source": [
        "sent_deployment_token = '5a9b51df6b6f497a9d75487fb8b42131'\n",
        "sent_deployment_id = '3714f6bd0'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a7746606",
      "metadata": {
        "id": "a7746606",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5deef48a-547b-4326-c845-d83f6f2f9255"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 100/100 [00:41<00:00,  2.38it/s]\n"
          ]
        }
      ],
      "source": [
        "tqdm._instances.clear()\n",
        "sample_texts = data['review'][:100]\n",
        "sentiments = [\n",
        "    client.get_sentiment(\n",
        "        deployment_token=sent_deployment_token,\n",
        "        deployment_id=sent_deployment_id,\n",
        "        document=text\n",
        "    )\n",
        "    for text in tqdm(sample_texts)\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b4aae3d8",
      "metadata": {
        "id": "b4aae3d8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        },
        "outputId": "605ee53d-48b4-4bd0-ce61-0b8a97f98492"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Top scoring texts for: \"joy\"\n",
            "\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-10-d748ee34f693>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mquery\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'joy'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'Top scoring texts for: \"{query}\"\\n'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mscores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ms\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msentiments\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0marg_sort\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margsort\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscores\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0marg_sort\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-10-d748ee34f693>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mquery\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'joy'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'Top scoring texts for: \"{query}\"\\n'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mscores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ms\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msentiments\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0marg_sort\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margsort\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscores\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0marg_sort\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'joy'"
          ]
        }
      ],
      "source": [
        "query = 'joy'\n",
        "print(f'Top scoring texts for: \"{query}\"\\n')\n",
        "scores = [s[query] for s in sentiments]\n",
        "arg_sort = np.argsort(-np.array(scores))\n",
        "for i in arg_sort[:5]:\n",
        "    print(scores[i])\n",
        "    print(sample_texts[i])\n",
        "    print('')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "30a99586",
      "metadata": {
        "id": "30a99586"
      },
      "outputs": [],
      "source": [
        "query = 'annoyance'\n",
        "print(f'Top scoring texts for: \"{query}\"\\n')\n",
        "scores = [s[query] for s in sentiments]\n",
        "arg_sort = np.argsort(-np.array(scores))\n",
        "for i in arg_sort[:5]:\n",
        "    print(scores[i])\n",
        "    print(sample_texts[i])\n",
        "    print('')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "28ff9381",
      "metadata": {
        "id": "28ff9381"
      },
      "outputs": [],
      "source": [
        "query = 'fear'\n",
        "print(f'Top scoring texts for: \"{query}\"\\n')\n",
        "scores = [s[query] for s in sentiments]\n",
        "arg_sort = np.argsort(-np.array(scores))\n",
        "for i in arg_sort[:5]:\n",
        "    print(scores[i])\n",
        "    print(sample_texts[i])\n",
        "    print('')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d76674c2",
      "metadata": {
        "id": "d76674c2"
      },
      "source": [
        "# Create a classification model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c79d4303",
      "metadata": {
        "id": "c79d4303",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0a238e33-60f2-4ed8-a164-b204a34a38cc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Creating project\n",
            "Training model\n",
            "Deploying model\n",
            "Model deployed\n"
          ]
        }
      ],
      "source": [
        "print('Creating project')\n",
        "class_project = api_client.create_project('nlp_classification', use_case='NLP_CLASSIFICATION')\n",
        "\n",
        "api_client.add_feature_group_to_project(\n",
        "    feature_group_id=feature_group, project_id=class_project, feature_group_type='DOCUMENTS'\n",
        ")\n",
        "\n",
        "class_project.set_feature_mapping(\n",
        "    feature_group_id=feature_group,\n",
        "    feature_name='review',\n",
        "    feature_mapping='DOCUMENT',\n",
        ")\n",
        "\n",
        "print('Training model')\n",
        "class_model = class_project.train_model(\n",
        "    name='classification_model_1',\n",
        "    training_config={\n",
        "        'zero_shot_hypotheses': [\n",
        "            'This text is about car speed / acceleration / slowness',\n",
        "            'This text is about car price / cost / value for money',\n",
        "            'This text is about car build quality',\n",
        "            'This text is about car seats',\n",
        "        ]\n",
        "    }\n",
        ")\n",
        "\n",
        "class_model = class_model.wait_for_full_automl()\n",
        "print('Deploying model')\n",
        "class_deployment = api_client.create_deployment(model_id=class_model)\n",
        "class_deployment = class_deployment.wait_for_deployment()\n",
        "class_deployment_token = class_project.create_deployment_token()\n",
        "class_deployment_id = class_deployment.deployment_id\n",
        "\n",
        "print('Model deployed')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "69a3c102",
      "metadata": {
        "id": "69a3c102",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 252
        },
        "outputId": "32730bc4-21df-49e6-d3de-4186f76be31f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Testing prediction\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-659b14ca9b68>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Testing prediction'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m client.get_classification(\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mdeployment_token\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclass_deployment_token\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mdeployment_id\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclass_deployment_id\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mdocument\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"This car is a bargain.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'client' is not defined"
          ]
        }
      ],
      "source": [
        "print('Testing prediction')\n",
        "client.get_classification(\n",
        "    deployment_token=class_deployment_token,\n",
        "    deployment_id=class_deployment_id,\n",
        "    document=\"This car is a bargain.\"\n",
        ")\n",
        "\n",
        "sample_texts = data['review'][:100]\n",
        "text_classifications = []\n",
        "\n",
        "text_to_prediction = {}\n",
        "\n",
        "print('Producing predictions')\n",
        "\n",
        "# Produce predictions in the background so we can do some analysis straight away\n",
        "\n",
        "def process_data(texts):\n",
        "    for text in texts:\n",
        "        text_to_prediction[text] = client.get_classification(\n",
        "            deployment_token=class_deployment_token,\n",
        "            deployment_id=class_deployment_id,\n",
        "            document=text,\n",
        "        )\n",
        "        \n",
        "thread = threading.Thread(target=process_data, args=(sample_texts,))\n",
        "thread.start()\n",
        "\n",
        "while len(text_to_prediction) < 20:\n",
        "    IPython.display.clear_output(wait=True)\n",
        "    print(f'Predictions produced so far: {len(text_to_prediction)}')\n",
        "    time.sleep(1)\n",
        "print('Example prediction:')\n",
        "list(text_to_prediction.values())[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d8acbf22",
      "metadata": {
        "id": "d8acbf22"
      },
      "outputs": [],
      "source": [
        "predictions = []\n",
        "for text in sample_texts:\n",
        "    if text not in text_to_prediction:\n",
        "        break\n",
        "    else:\n",
        "        predictions.append(text_to_prediction[text])\n",
        "print(f'Predictions made so far: {len(predictions)}\\n')\n",
        "query = list(predictions[0].keys())[1]\n",
        "print(f'Top scoring texts for: \"{query}\"\\n')\n",
        "scores = [s[query] for s in predictions]\n",
        "arg_sort = np.argsort(-np.array(scores))\n",
        "for i in arg_sort[:5]:\n",
        "    print(f'Score = {scores[i]}')\n",
        "    print(sample_texts[i])\n",
        "    print('')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f2973945",
      "metadata": {
        "id": "f2973945"
      },
      "source": [
        "# Build a named entity recognition (NER) model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "645be391",
      "metadata": {
        "id": "645be391"
      },
      "outputs": [],
      "source": [
        "ner_project = api_client.create_project('named_entity_recognition', use_case='NAMED_ENTITY_RECOGNITION')\n",
        "\n",
        "api_client.add_feature_group_to_project(\n",
        "    feature_group_id=feature_group, project_id=ner_project, feature_group_type='DOCUMENTS'\n",
        ")\n",
        "\n",
        "ner_project.set_feature_mapping(\n",
        "    feature_group_id=feature_group,\n",
        "    feature_name='review',\n",
        "    feature_mapping='DOCUMENT',\n",
        ")\n",
        "\n",
        "ner_model = ner_project.train_model(\n",
        "    name='ner_model_1',\n",
        "    training_config={'NER_MODEL_TYPE': \"pretrained uncased 43 categories\"}\n",
        ")\n",
        "\n",
        "ner_model.wait_for_full_automl()\n",
        "\n",
        "ner_deployment = api_client.create_deployment(model_id=ner_model)\n",
        "\n",
        "ner_deployment = ner_deployment.wait_for_deployment()\n",
        "\n",
        "ner_deployment_token = ner_project.create_deployment_token()\n",
        "\n",
        "ner_deployment_id = ner_deployment.deployment_id\n",
        "ner_deployment_token = ner_deployment_token\n",
        "\n",
        "client.get_labels(deployment_token=ner_deployment_token, deployment_id=ner_deployment_id, query_data={\"content\":\"I love my Toyota Camry!\"})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "17ed4a48",
      "metadata": {
        "id": "17ed4a48"
      },
      "outputs": [],
      "source": [
        "tqdm._instances.clear()\n",
        "sample_texts = data['review'][:100]\n",
        "annotations = [\n",
        "    client.get_labels(deployment_token=ner_deployment_token, deployment_id=ner_deployment_id, query_data={'content': text})['annotations']\n",
        "    for text in tqdm(sample_texts)\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6aba53fd",
      "metadata": {
        "id": "6aba53fd"
      },
      "outputs": [],
      "source": [
        "label_counts = collections.Counter([anno['displayName'] for anno_list in annotations for anno in anno_list])\n",
        "label_counts.most_common(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1411db68",
      "metadata": {
        "id": "1411db68"
      },
      "outputs": [],
      "source": [
        "product_counts = collections.Counter([anno['textExtraction']['textSegment']['phrase'].strip().lower()\n",
        "                                      for anno_list in annotations for anno in anno_list if anno['displayName'] == 'product'])\n",
        "product_counts.most_common(10)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d70bd419",
      "metadata": {
        "id": "d70bd419"
      },
      "source": [
        "# Combined analysis using multiple models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b460b843",
      "metadata": {
        "id": "b460b843"
      },
      "outputs": [],
      "source": [
        "# Filter using NER\n",
        "\n",
        "filtered_texts = [\n",
        "    text\n",
        "    for text, anno_list in zip(sample_texts, annotations)\n",
        "    if any([anno['displayName'] == 'product' and 'avalon' in anno['textExtraction']['textSegment']['phrase'].strip().lower()\n",
        "           for anno in anno_list])\n",
        "]\n",
        "len(filtered_texts)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b2a30bde",
      "metadata": {
        "id": "b2a30bde"
      },
      "outputs": [],
      "source": [
        "# See top scores after the filter\n",
        "\n",
        "predictions = []\n",
        "for text in filtered_texts:\n",
        "    if text not in text_to_prediction:\n",
        "        break\n",
        "    else:\n",
        "        predictions.append(text_to_prediction[text])\n",
        "query = list(predictions[0].keys())[1]\n",
        "print(f'Top scoring texts for: \"{query}\"\\n')\n",
        "scores = [s[query] for s in predictions]\n",
        "arg_sort = np.argsort(-np.array(scores))\n",
        "for i in arg_sort[:5]:\n",
        "    print(scores[i])\n",
        "    print(filtered_texts[i])\n",
        "    print('')"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    },
    "colab": {
      "name": "Abacus AI NLP Workshop.ipynb",
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}